{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analyse des tendances de prix des ordinateurs portables sur eBay**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Projet réalisé par Antony Albergne, Adam Belkhatir et Noéline Casteil*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Notre projet vise à étudier les tendances de consommation des utilisateurs de plateformes de e-commerce, en se concentrant sur les ordinateurs portables sur eBay. Les questions centrales de cette étude sont les suivantes :\n",
    "- Quels sont les facteurs qui influencent la demande d’un produit et, par conséquent, son prix ?\n",
    "- Comment estimer le prix d’un ordinateur en fonction de ses caractéristiques ?\n",
    "\n",
    "Pour y répondre, nous avons distingué deux types de critères :\n",
    "\n",
    "**Critères objectifs :** RAM, stockage, densité de pixels, condition de l’article, taille de l'écran.\n",
    "\n",
    "**Critères subjectifs :** marque ou couleur.\n",
    "\n",
    "Nous jugeons que ces critères sont suffisants pour évaluer la qualité d'un ordinateur. En particulier, la RAM se trouve être un bon proxy de la puissance d'un ordinateur car une grande capacité de mémoire vive est souvent associée à d’autres composants haut de gamme. Les fabricants équipent généralement les ordinateurs dotés de beaucoup de RAM avec des processeurs rapides, des disques SSD performants et des cartes graphiques puissantes, ce qui en fait un signal fiable d'une configuration globale de qualité.\n",
    "\n",
    "Nous avons trouvé le choix de la plateforme eBay pertinent dans la mesure où ce sont les utilisateurs qui fixent le prix qu'ils attribuent à leur ordinateur. Cette dynamique permet d’évaluer si les vendeurs sont objectifs dans leur valorisation du produit ou si le prix fixé est cohérent avec les caractéristiques de l’ordinateur. Grâce aux tendances observées, il devient possible de déterminer si ces prix reflètent réellement la valeur des produits.\n",
    "\n",
    "Afin d’analyser ces influences, nous avons choisi de modéliser la relation entre les caractéristiques des produits et leur prix à l’aide d’une régression linéaire. Cette approche permet de quantifier l’impact de chaque critère sur le prix des ordinateurs portables. Nous pourrons ainsi mieux comprendre comment les utilisateurs déterminent le prix de vente de leurs ordinateurs portables et savoir si certaines variables les influencent plus que d'autres. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sommaire**\n",
    "- [Installation](#1-installation)\n",
    "- [Chargement des données](#2-chargement-des-données-dans-le-projet)\n",
    "    - [Données eBay](#21-données-ebay)\n",
    "    - [Données du scraping](#22-données-issues-de-scraping)\n",
    "        - [Récupération du coefficient de popularité](#221-récupération-du-coefficient-de-popularité)\n",
    "        - [Récupération du Rang](#222-récupération-du-rang)\n",
    "- [Nettoyage des données](#3-nettoyage-des-données)\n",
    "    - [Données chiffrées](#31-nettoyage-des-données-chiffrées)\n",
    "    - [Données temporelles](#32-nettoyage-des-données-temporelles)\n",
    "    - [Données textuelles](#33-nettoyage-des-données-textuelles)\n",
    "    - [Gestion valeur aberrantes](#34-gestion-des-valeurs-aberrantes)\n",
    "- [Visualisation](#4-visualisation)\n",
    "    - [Aperçu général](#41-un-aperçu-global)\n",
    "    - [Analyse des variables](#42-analyse-des-variables)\n",
    "        - [Prix](#421-la-variable-prix)\n",
    "        - [Densité de pixels](#421-les-prix-en-fonction-de-la-densité-de-pixels)\n",
    "        - [Condition](#423-la-variable-condition)\n",
    "        - [Marque](#425-analyse-de-la-marque)\n",
    "        - [Popularité](#426-lien-entre-la-popularité-de-la-marque-et-de-larticle)\n",
    "        - [Temporalité](#427--analyse-de-la-temporalité)\n",
    "- [Modélisation](#5-modélisation)\n",
    "    - [Prétraitrement des données](#51-prétraitement-des-données)\n",
    "        - [Encodage des colonnes catégoriques](#511-encodage-des-colonnes-catégoriques)\n",
    "        - [Gestion des valeurs manquantes](#512-gestion-des-valeurs-manquantes)\n",
    "        - [Normalisation des valeurs](#513-normalisation-des-valeurs)\n",
    "        - [Séparation des données](#514-séparation-des-données-en-ensembles-dentraînement-et-de-test)\n",
    "    - [Exécution du modèle](#52-exécution-du-modèle)\n",
    "        - [Le modèle de régression linéaire](#521-le-modèle-de-régression-linéaire)\n",
    "        - [Interprétation des résultats](#522-interprétation-des-résultats)\n",
    "        - [Qualité du modèle](#6-qualité-du-modèle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (4.12.3)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.8.2)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.13.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (3.11.11)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.6.0)\n",
      "Requirement already satisfied: nest_asyncio in /Users/noelinecasteil/Library/Python/3.12/lib/python/site-packages (from -r requirements.txt (line 9)) (1.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->-r requirements.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->-r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->-r requirements.txt (line 2)) (2023.11.17)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4->-r requirements.txt (line 3)) (2.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (3.1.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->-r requirements.txt (line 7)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->-r requirements.txt (line 7)) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->-r requirements.txt (line 7)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->-r requirements.txt (line 7)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->-r requirements.txt (line 7)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->-r requirements.txt (line 7)) (1.18.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Chargement des données dans le projet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1 Données eBay**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En raison du temps de réponse élevé de l’API et du nombre d'appels à l'API limité à 5000 par jour, nous avons préféré exécuter les requêtes en amont et sauvegarder les données dans un fichier `.csv`. Cette démarche a pour objectif de faciliter l’analyse en évitant les délais d’attente liés à l’API et en permettant d'avoir plus de données. \n",
    "\n",
    "Le code permettant de collecter les données est disponible sur le GitHub du projet. Ce script `data.py` situé dans le fichier `src` peut être exécuté en suivant les instructions du README pour l'accès à l'API si de nouvelles données doivent être extraites.\n",
    "\n",
    "Dans le notebook, nous nous contentons de charger le fichier `.csv` prégénéré pour effectuer les étapes d’analyse et de nettoyage.\n",
    "\n",
    "Cette approche permet une expérience plus fluide et garantit la reproductibilité de l’étude sans dépendre des performances de l’API au moment de l’exécution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Récupération des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pour collecter les données nécessaires à notre étude, nous avons utilisé l’API Browse d’eBay. Ce choix s’explique par la richesse des informations disponibles sur cette plateforme et son large catalogue de produits. Cependant, cela a requis plusieurs étapes préparatoires :\n",
    "\n",
    "1. **Choix d'un segment spécifique :** Pour limiter la variabilité des données, nous avons choisi de nous concentrer sur les ordinateurs portables. Ce segment présente de nombreuses spécificités (RAM, stockage, écran, etc.) qui permettent d’étudier l’impact de chaque critère sur le prix.\n",
    "\n",
    "2. **Délimitation du marché :** Nous avons choisi de nous focaliser sur le marché français. Cette décision a pour but d’éviter les biais liés à des contextes géopolitiques différents entre les marchés ou à des devises différentes. \n",
    "\n",
    "3. **Extraction des données :**\n",
    "Les informations classiques comme le prix et l’état des articles sont directement accessibles via l’API Browse pour chaque item.\n",
    "Les caractéristiques plus précises (RAM, marque, stockage, taille de l’écran) sont stockées dans une sous-catégorie nommée *localized aspects*. Ces informations sont organisées sous forme de dictionnaire (clé/valeur).\n",
    "\n",
    "4. **Gestion des données manquantes :**\n",
    "Comme les utilisateurs remplissent eux-mêmes les informations, certaines données sont parfois absentes. \n",
    "Plusieurs approches ont été envisagées :\n",
    "    - Exclure les articles avec des données manquantes, en raison du volume important de données disponibles.\n",
    "    - Conserver les articles incomplets pour ne pas réduire excessivement l’échantillon.\n",
    "\n",
    "Afin de ne pas trop réduire l'échantillon ou de compromettre la fiabilité de l'étude nous avons choisi de conserver les articles ayant obligatoirement les informations suivantes : prix, capacité de stockage, RAM et marque. Toutefois, si des données telles que la taille de l'écran, la résolution ou encore la date de publication ne sont pas présentes il ne nous semblait pas pertinent d'enlever ces ordinateurs portables puisque cela ne compromet pas le résultat de notre étude et nous permet d'avoir un échantillon plus important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Données issues de scraping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 **Récupération du coefficient de popularité**\n",
    "\n",
    "Dans un second temps, nous avons jugé pertinent de mesurer la popularité des articles présents sur le site eBay. Pour cela, nous avons défini un coefficient de popularité construit à partir des informations suivantes, obtenues grâce au scraping :\n",
    "\n",
    "- **Want :** Nombre de personnes actuellement intéressées par l’article (le consultent activement).\n",
    "- **Watched :** Nombre de personnes ayant vu l’article au cours des dernières 24 heures.\n",
    "- **Watchlist :** Nombre de personnes ayant ajouté l’article à leur liste de surveillance.\n",
    "- **Sold :** Nombre d’exemplaires déjà vendus de cet article.\n",
    "\n",
    "$$\n",
    "\\text{Coefficient de popularité}= \\frac{{\\text{Watched} + 2*\\text{Want} + 3*\\text{Sold} + 2*\\text{Watchlist}}}{8}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code associé à la récupération du coefficient et du rang peut prendre un certain temps. Comme précédemment, par souci de reproductibilité du code, nous avons choisi de faire tourner le scraping dans un fichier à part `scraping.py`. Le coefficient est construit pour être une mesure en temps réel de la popularité d'un produit, les coefficients ainsi utilisé dans le notebook reflète leur popularité à un moment donné, à savoir le dernier jour d'exécution du programme.\n",
    "\n",
    "Les données récupérées grâce à l'API d'eBay et au scraping sont compilées dans `final_data.csv` qui est ainsi notre data frame complet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Condition</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Stockage</th>\n",
       "      <th>Marque</th>\n",
       "      <th>Couleur</th>\n",
       "      <th>Taille écran</th>\n",
       "      <th>Résolution</th>\n",
       "      <th>Date de publication</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v1|176737201854|0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>16 Go</td>\n",
       "      <td>0</td>\n",
       "      <td>ASUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,4\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-15T17:33:06.000Z</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v1|375863586836|0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>8 Go</td>\n",
       "      <td>256 Go</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Gris</td>\n",
       "      <td>13\"</td>\n",
       "      <td>2560 x 1600</td>\n",
       "      <td>2024-12-13T08:42:48.000Z</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v1|146269671817|0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>6 Go</td>\n",
       "      <td>700Go</td>\n",
       "      <td>ASUS</td>\n",
       "      <td>Rouge</td>\n",
       "      <td>15,6\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-15T11:51:11.000Z</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v1|196898961056|0</td>\n",
       "      <td>89.9</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>8 Go</td>\n",
       "      <td>480Go</td>\n",
       "      <td>HP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17,3\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-17T16:37:02.000Z</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v1|365291982473|0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>16 Go</td>\n",
       "      <td>256 Go</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Noir</td>\n",
       "      <td>13\"</td>\n",
       "      <td>1920 x 1080</td>\n",
       "      <td>2024-12-17T16:57:08.000Z</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>v1|235873614482|0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>4 Go</td>\n",
       "      <td>64 Go</td>\n",
       "      <td>HP</td>\n",
       "      <td>Blanc</td>\n",
       "      <td>14,1\"</td>\n",
       "      <td>1366 x 768</td>\n",
       "      <td>2024-12-16T18:07:16.000Z</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>v1|226501515887|0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>8 Go</td>\n",
       "      <td>128 Go</td>\n",
       "      <td>ASUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-17T21:45:30.000Z</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>v1|326373954761|0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>Ouvert (jamais utilisé)</td>\n",
       "      <td>16 Go</td>\n",
       "      <td>256 Go</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Gris</td>\n",
       "      <td>14\"</td>\n",
       "      <td>1920 x 1080</td>\n",
       "      <td>2024-12-16T19:12:19.000Z</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>v1|176738106689|0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>4 Go</td>\n",
       "      <td>160 Go</td>\n",
       "      <td>Toshiba</td>\n",
       "      <td>Blanc</td>\n",
       "      <td>15,6\"</td>\n",
       "      <td>1366 x 768</td>\n",
       "      <td>2024-12-16T06:37:45.000Z</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>v1|196734278702|0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>Très bon état - Reconditionné</td>\n",
       "      <td>8Go</td>\n",
       "      <td>HD 620</td>\n",
       "      <td>Panasonic</td>\n",
       "      <td>Noir</td>\n",
       "      <td>12\" LED 2160 * 1440</td>\n",
       "      <td>titre</td>\n",
       "      <td>2024-10-19T09:22:26.000Z</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID    Prix                      Condition    RAM Stockage  \\\n",
       "0  v1|176737201854|0  1680.0                       Occasion  16 Go        0   \n",
       "1  v1|375863586836|0   550.0                       Occasion   8 Go   256 Go   \n",
       "2  v1|146269671817|0   120.0                       Occasion   6 Go    700Go   \n",
       "3  v1|196898961056|0    89.9                       Occasion   8 Go    480Go   \n",
       "4  v1|365291982473|0  1300.0                       Occasion  16 Go   256 Go   \n",
       "5  v1|235873614482|0    75.0                       Occasion   4 Go    64 Go   \n",
       "6  v1|226501515887|0   230.0                       Occasion   8 Go   128 Go   \n",
       "7  v1|326373954761|0   340.0        Ouvert (jamais utilisé)  16 Go   256 Go   \n",
       "8  v1|176738106689|0    49.0                       Occasion   4 Go   160 Go   \n",
       "9  v1|196734278702|0   169.0  Très bon état - Reconditionné    8Go   HD 620   \n",
       "\n",
       "      Marque Couleur         Taille écran   Résolution  \\\n",
       "0       ASUS     NaN                13,4\"          NaN   \n",
       "1      Apple    Gris                  13\"  2560 x 1600   \n",
       "2       ASUS   Rouge                15,6\"          NaN   \n",
       "3         HP     NaN                17,3\"          NaN   \n",
       "4       Dell    Noir                  13\"  1920 x 1080   \n",
       "5         HP   Blanc                14,1\"   1366 x 768   \n",
       "6       ASUS     NaN                  14\"          NaN   \n",
       "7       Dell    Gris                  14\"  1920 x 1080   \n",
       "8    Toshiba   Blanc                15,6\"   1366 x 768   \n",
       "9  Panasonic    Noir  12\" LED 2160 * 1440        titre   \n",
       "\n",
       "        Date de publication  Coefficient  \n",
       "0  2024-12-15T17:33:06.000Z         0.00  \n",
       "1  2024-12-13T08:42:48.000Z         5.75  \n",
       "2  2024-12-15T11:51:11.000Z         0.00  \n",
       "3  2024-12-17T16:37:02.000Z         0.00  \n",
       "4  2024-12-17T16:57:08.000Z         1.00  \n",
       "5  2024-12-16T18:07:16.000Z         0.00  \n",
       "6  2024-12-17T21:45:30.000Z         0.00  \n",
       "7  2024-12-16T19:12:19.000Z         0.00  \n",
       "8  2024-12-16T06:37:45.000Z         0.75  \n",
       "9  2024-10-19T09:22:26.000Z         6.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils import load_data\n",
    "df = load_data(\"final_data.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 **Récupération du Rang**\n",
    "\n",
    "Dès le début du projet, nous avons supposé que la popularité de la marque influencerait les résultats. Il nous a donc semblé pertinent de rechercher des classements de popularité des marques high-tech sur le marché. Pour ce faire, nous avons procédé à un processus de scraping afin d'obtenir un classement moyen à partir de plusieurs sites internet.\n",
    "\n",
    "Nous avons développé un script de scraping permettant d’attribuer à chaque marque un classement de popularité, intégré dans une colonne intitulée *Rang* du DataFrame. Ce rang a été calculé à partir des classements de six sites web figurant parmi les premiers résultats d’une recherche sur les “classements des ordinateurs”. En combinant ces différentes sources, nous avons effectué une moyenne pour déterminer le rang final de chaque marque, que nous avons ensuite ajouté à la colonne correspondante. Les différents sites sont : \n",
    "- Le Parisien\n",
    "- LaptopSpirit\n",
    "- GeekWise\n",
    "- FormationMax\n",
    "- Test-Achats\n",
    "- ApprendreInformatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelinecasteil/Library/Python/3.12/lib/python/site-packages/pygments/formatters/terminal256.py:180: RuntimeWarning: coroutine 'process_batch' was never awaited\n",
      "  self.xterm_colors.append((r, g, b))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscraping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_rang\n\u001b[1;32m      2\u001b[0m get_rang(df)\n",
      "File \u001b[0;32m~/Desktop/Projet_evaluation_prix_eBay/src/scraping.py:85\u001b[0m\n\u001b[1;32m     82\u001b[0m     df1\u001b[38;5;241m.\u001b[39mto_csv(output_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFichier CSV généré : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[43mget_coefficient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinal_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#On sépare en paquet de 100 pour aller plus vite\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#Dictionnaire qui contient le classement pondéré de tout les sites\u001b[39;00m\n\u001b[1;32m     90\u001b[0m Classements \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Desktop/Projet_evaluation_prix_eBay/src/scraping.py:75\u001b[0m, in \u001b[0;36mget_coefficient\u001b[0;34m(df1, batch_size, output_file)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m     df_batch \u001b[38;5;241m=\u001b[39m new_items_df\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m---> 75\u001b[0m     L_coeff \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     df1\u001b[38;5;241m.\u001b[39mloc[df_batch\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m L_coeff\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#On initilialise à 0.0 les coef pour ceux qui n'en ont pas\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "from src.scraping import get_rang\n",
    "get_rang(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Nettoyage des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme évoqué plus tôt, la particularité des données récoltées est qu'elles ont été entrées par les vendeurs eux-mêmes via la plateforme. Ainsi, si le nom de la catégorie (ex: *RAM*, *Stockage*) est le même pour chaque produit, les informations contenues dans chaque colonne différent dans leur format. Par défaut, toutes les données sont de type \"*object*\" ce qui ne les rend pas exploitable directement pour nous. Le travail de nettoyage est ainsi essentiel afin d'avancer sur notre projet.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 **Nettoyage des données chiffrées**\n",
    "\n",
    "Pour cela, nous avons créé une fonction `extract_float_from_object` au sein du fichier `utils.py` qui permet d'extraire un nombre de type float à partir d'une chaîne de caractère. Nous pouvons appliquer cette fonction directement pour la catégorie *Taille écran*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import extract_float_from_object, extract_storage\n",
    "\n",
    "df['Taille écran'] = df['Taille écran'].apply(extract_float_from_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour gérer les catégories liées au stockage dont les données étaient soit rentrées en Go, soit en To, nous avons créé une seconde fonction dérivée de la première, mais qui effectue la conversion en Go pour les données entrées en To, selon la formule $1To = 1024 Go$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RAM'] = df['RAM'].apply(extract_storage)\n",
    "df['Stockage'] = df['Stockage'].apply(extract_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, pour gérer la colonne résolution dont le format est le suivant : $Largeur \\times Hauteur$, nous avons choisi de combiner cette information avec la taille de l'écran pour établir une mesure comparable entre tous les ordinateurs du data frame : la **densité de pixels (PPI)**.\n",
    "\n",
    "$$\n",
    "Densité\\ de\\ pixels = \\frac{\\sqrt{\\text{largeur}^2 + \\text{hauteur}^2}}{\\text{taille de l'écran en pouces}}\n",
    "$$\n",
    "\n",
    "On commence par extraire la largeur et la hauteur dans deux nouvelles colonnes, et on utilise ensuite la formule ci-dessus pour créer la colonne *PPI* que l'on conservera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction de la résolution dans deux nouvelles colonnes\n",
    "df[['Largeur', 'Hauteur']] = df['Résolution'].str.extract(r'(\\d+)[\\s]*[xX][\\s]*(\\d+)', expand=True)\n",
    "df[['Largeur', 'Hauteur']] = df[['Largeur', 'Hauteur']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#Calcul du PPI\n",
    "df['Taille écran'] = df['Taille écran'].apply(extract_float_from_object)\n",
    "df[['Largeur', 'Hauteur', 'Taille écran']] = df[['Largeur', 'Hauteur', 'Taille écran']].replace(0, np.nan)\n",
    "# On calcule le PPI uniquement pour les lignes où toutes les valeurs nécessaires sont présentes\n",
    "mask = df[['Largeur', 'Hauteur', 'Taille écran']].notnull().all(axis=1)\n",
    "df.loc[mask, 'PPI'] = np.round(np.sqrt(df.loc[mask, 'Largeur']**2 + df.loc[mask, 'Hauteur']**2) / df.loc[mask, 'Taille écran'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 **Nettoyage des données temporelles**\n",
    "\n",
    "Cela concerne uniquement la colonne **Date de publication**. Ici, le format est idéal car c'est une information qui nous est fournie directement par eBay. On utilise alors la fonction intégrée à pandas `pd.to_datetime()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date de publication'] = pd.to_datetime(df['Date de publication'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 **Nettoyage des données textuelles**\n",
    "\n",
    "Cela concerne les colonnes *Condition*, *Marque* et *Couleur*. Ici, l'enjeu est d'uniformiser les données afin de rassembler toutes les données identiques de fait mais rentrées différemment par les utilisateurs. \n",
    "\n",
    "Pour cela, nous faison appel à des fonctions codées dans le fichier `cleaning.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cleaning import normalize_color, convertir_condition, format_marque\n",
    "\n",
    "#Normalisation des couleurs\n",
    "df['Couleur'] = df['Couleur'].apply(normalize_color)\n",
    "\n",
    "#Normalisation des conditions     \n",
    "df['Condition'] = df['Condition'].apply(convertir_condition)\n",
    "\n",
    "#Normalisation des marques\n",
    "df['Marque'] = df['Marque'].apply(format_marque)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se débarasse des colonnes qui nous seront inutiles pour la suite. En particulier, la colonne résolution est remplacée par la colonne *PPI* qui compile taille de l'écran et résolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Largeur', 'Hauteur', 'Résolution'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir notre data frame final, il reste encore à gérer les valeurs aberrantes qui sont assez fréquentes du fait des erreurs ou mauvais choix des utilisateurs eBay.\n",
    "\n",
    "### 3.4 **Gestion des valeurs aberrantes**\n",
    "\n",
    "Un bon outil pour repérer les valeurs aberrantes est la boîte à moustache qui nous donne une vision claire de la répartition des données pour chaque catégorie. On peut la générer pour chaque colonne grâce à la fonction suivante. Par souci de lisibilité, nous génèrerons seulement la boîte à moustache de la variable *Prix*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(df, column_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=df[column_name])\n",
    "    plt.title(f'Boxplot of {column_name}')\n",
    "    plt.xlabel(column_name)\n",
    "    plt.show()\n",
    "\n",
    "boxplot(df, 'Prix')\n",
    "#boxplot(df, 'Stockage')\n",
    "#boxplot(df, 'RAM')\n",
    "#boxplot(df, 'PPI')\n",
    "#boxplot(df, 'Taille écran')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce à ces boites à moustache ainsi qu'à une connaissance des caractéristiques des ordinateurs portables modernes, on établit une plage cohérente pour chaque colonne. Toute donnée à l'extérieur de ces plages est considérée comme \"aberrante\" et est gérée en fonction. \n",
    "\n",
    "**Caractéristiques des plages** :\n",
    "\n",
    "- **Plage des prix** : $[50\\ € ;\\ 3000\\ €]$\n",
    "- **Plage de la densité de pixels** : $[80\\ \\text{PPI} ;\\ 300\\ \\text{PPI}]$\n",
    "- **Plage de la capacité de stockage** : $[32\\ \\text{Go} ;\\ 4000\\ \\text{Go}]$\n",
    "- **Plage de la capacité de RAM** : $[2\\ \\text{Go} ;\\ 64\\ \\text{Go}]$\n",
    "- **Plage de la taille d’écran** : $[6'' ;\\ 20'']$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Prix'] >= 50) & (df['Prix'] <= 3000)]  \n",
    "df.loc[(df['PPI'] > 300) | (df['PPI'] < 80), 'PPI'] = np.nan\n",
    "# énormément de gens se trompent en mettant la même valeur pour la RAM et le stockage\n",
    "df.loc[(df['Stockage'] < 32) | (df['Stockage'] > 4000), 'Stockage'] = np.nan  \n",
    "df.loc[(df['RAM'] < 2) | (df['RAM'] > 64), 'RAM'] = np.nan  \n",
    "df.loc[(df['Taille écran'] < 6) | (df['Taille écran'] > 20), 'Taille écran'] = np.nan  \n",
    "\n",
    "boxplot(df, 'Prix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etant donné que l'on cherche à estimer le prix, et que les prix aberrants représente un nombre négligeable de données sur l'ensemble de notre data frame, nous avons décidé de supprimer les lignes où les prix étaient en effet aberrants. Pour les autres variables, nous avons décidé de les remplacer par des `NaN` pour les exclure de la visualisation sans se priver de l'information que nous apporte les autres données de cet ordinateur. Ces valeurs manquantes seront remplacées lors de la modélisation.\n",
    "\n",
    "Notre data frame est à présent nettoyé, nous allons pouvoir commencer à l'analyser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Visualisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 **Un aperçu global**\n",
    "\n",
    "Pour commencer, la fonctions `info` intégrée à la bibliothèque *pandas* nous donnent un aperçu de notre data frame et de ses caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que beaucoup de valeurs sont manquantes pour la densité de pixels. Nous considérons cependant que le nombre d'observations demeure assez élevé pour identifier son effet sur les prix. \n",
    "De manière générale, nous faisons l'hypothèse que les valeurs manquantes ne reflète pas un biais car elles sont issues des informations entrées par les vendeurs indépendants qui peuvent vendre n'importe quel type d'ordinateurs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 **Analyse des variables**\n",
    "\n",
    "#### 4.2.1 **La variable Prix**\n",
    "Nous pouvons pour commencer, analyser les distributions de prix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_log_distribution(df, column):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[column].apply(lambda x: np.log(x + 1)), bins=30, color='skyblue', kde=False, alpha=0.7)\n",
    "    plt.title(f\"Distribution logarithmique de {column}\", fontsize=16)\n",
    "    plt.xlabel(f\"Logarithme de {column}\", fontsize=14)\n",
    "    plt.ylabel(\"Nombre\", fontsize=14)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_log_distribution(df,'Prix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique représente la distribution logarithmique des prix des ordinateurs portables, permettant une meilleure visualisation des données initialement asymétriques. La distribution semble montrer une forme unimodale avec un seul pic autour de $5.5$ en logarithme. \n",
    "\n",
    "Cette concentration autour de $5.5$ suggère qu'une grande partie des ordinateurs portables se situe dans une gamme de prix cohérente après transformation. \n",
    "Toutefois la présence d'une queue gauche ressérée suggère qu'il y a peu d'ordinateurs dans des gammes de prix très basses tandis que la queue droite étendue pourrait suggérer la présence de modèles haut de gamme tirant les prix vers le haut. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La concentration d'une valeur centrale indique une cohérence générale des données. Cette cohérence nous permet de procéder à l’étude des facteurs influençant le prix sans être excessivement perturbés par des valeurs aberrantes ou des distributions irrégulières."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 **Les prix en fonction de la densité de pixels**\n",
    "\n",
    "Pour visualiser la relation entre la densité de pixels (**PPI**) et le prix des ordinateurs portables, nous avons utilisé une régression linéaire simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price(df):\n",
    "    # Supprimer les lignes avec des valeurs NaN dans 'Prix' ou 'PPI'\n",
    "    df_clean = df.dropna(subset=['Prix', 'PPI'])\n",
    "    x = df_clean['PPI']\n",
    "    y = df_clean['Prix']\n",
    "    \n",
    "    # Calculer les coefficients de la régression linéaire\n",
    "    coefficients = np.polyfit(x, y, 1)  \n",
    "    trendline = np.poly1d(coefficients)\n",
    "    \n",
    "    # Création du graphique\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(x, y, c='blue', alpha=0.5, label=\"Données\")\n",
    "    \n",
    "    # Ajout de la droite de tendance\n",
    "    plt.plot(x, trendline(x), color='black', linewidth=2, label=\"Droite de tendance\")\n",
    "    \n",
    "    # Ajouter des labels et un titre\n",
    "    plt.title(\"Prix en fonction de la densité de pixels\")\n",
    "    plt.xlabel(\"Densité de pixels (PPI)\")\n",
    "    plt.ylabel(\"Prix (€)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "plot_price(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La visualisation montre une corrélation positive modérée entre le prix et le PPI. Cela signifie que les ordinateurs portables avec des écrans de meilleure qualité tendent à coûter plus cher. Cette corrélation n'est toutefois pas évidente au vu du graphique. Il serait sans doute pertinent de l'analyser plus en détail avec une régression linéaire plus approfondie tel que nous le ferons dans la partie modélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 **La variable Condition**\n",
    "Attardons nous à présent sur la qualité des ordinateurs : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = df['Condition'].value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné que la majorité des ordinateurs sont dans la catégorie *Occasion* (3209 sur 4033), il semble que l'état général du produit ne soit pas un critère pertinent pour expliquer les variations de prix. \n",
    "\n",
    "Une relation semble ici difficile à observer, toutefois nous avons décidé de ne pas éliminer la variable *Condition*. Les résultats de notre modèle pourrait nous apporter une vision plus claire de sa relation avec le prix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.5 **Analyse de la marque**\n",
    "\n",
    "Cette variable nous a semblé pertinente dans la mesure où la marque influence beaucoup la popularité des articles et donc pourrait par la suite influencer leur prix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgprice_brand(df):\n",
    "    \"\"\"\n",
    "    Calcule et affiche le prix moyen des ordinateurs portables par marque.\n",
    "    Cette fonction filtre les marques qui représentent moins de 5% du total des marques\n",
    "    et les regroupe sous l'étiquette 'Autres'\n",
    "    \"\"\"\n",
    "    brand_counts = df['Marque'].value_counts()\n",
    "    threshold = 0.05 * brand_counts.sum()  # Seuil de 5% pour les marques\n",
    "    filtered_brands = brand_counts[brand_counts >= threshold].index\n",
    "    df['Marque'] = df['Marque'].apply(lambda x: x if x in filtered_brands else 'Autres')\n",
    "\n",
    "    avg_price_by_brand = df.groupby('Marque')['Prix'].mean().sort_values()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=avg_price_by_brand.index, y=avg_price_by_brand.values)\n",
    "\n",
    "    plt.title(\"Prix moyen des ordinateurs portables par marque\", fontsize=16)\n",
    "    plt.xlabel(\"Marque\", fontsize=14)\n",
    "    plt.ylabel(\"Prix moyen (€)\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "avgprice_brand(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’histogramme montre qu’Apple affiche des prix nettement plus élevés. Néanmoins, cela pourrait s’expliquer par le fait qu’ils produisent des ordinateurs de meilleure qualité ; il serait donc pertinent d’analyser un graphique similaire en comparant des ordinateurs ayant des capacités équivalentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgprice_brand2(df):\n",
    "\n",
    "    # Filtrer les ordinateurs avec RAM de 8 Go et stockage de 256 Go\n",
    "    filter = df[(df['RAM'] == 8) & (df['Stockage'] == 256)]\n",
    "\n",
    "    # Calcul des marques représentant au moins 5% des occurrences\n",
    "    brand_counts = filter['Marque'].value_counts()\n",
    "    print(brand_counts)\n",
    "    threshold = 0.05 * brand_counts.sum()  # Seuil de 5% pour les marques\n",
    "    filtered_brands = brand_counts[brand_counts >= threshold].index\n",
    "    filter.loc[:, 'Marque'] = filter['Marque'].apply(lambda x: x if x in filtered_brands else 'Autres')\n",
    "\n",
    "    # Calcul du prix moyen par marque\n",
    "    avg_price_by_brand = filter.groupby('Marque')['Prix'].mean().sort_values()\n",
    "\n",
    "    # Création du graphique\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=avg_price_by_brand.index, y=avg_price_by_brand.values)\n",
    "\n",
    "    plt.title(\"Prix moyen des ordinateurs portables par marque (RAM: 8 Go, Stockage: 256 Go)\", fontsize=16)\n",
    "    plt.xlabel(\"Marque\", fontsize=14)\n",
    "    plt.ylabel(\"Prix moyen (€)\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.show()\n",
    "avgprice_brand2(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons ici choisi de sélectionner des ordinateurs présentant 8Go de RAM et 256Go de Stockage, des ordinateurs présentant donc les mêmes spécificités techniques. Pour autant le résultat reste le même : les ordinateurs Apple domine le marché en termes de prix de vente. Pour expliquer ceci nous pouvons nous pencher un peu plus sur la popularité des marques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique suivant utilise le rang que nous avons déterminé à l'aide des classements trouvés sur les différents sites internet. Nous affichons les prix moyens en fonction des rangs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_price_popularity(df):\n",
    "    popularity = df.groupby('Rang')['Prix'].mean()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x=popularity.index, y=popularity.values, marker='o')\n",
    "\n",
    "    plt.title(\"Impact de la popularité des marques sur les prix moyens\", fontsize=16)\n",
    "    plt.xlabel(\"Popularité (Classement)\", fontsize=14)\n",
    "    plt.ylabel(\"Prix moyen (€)\", fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.show()\n",
    "avg_price_popularity(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que la popularité des marques a un réel impact sur les prix des ordinateurs. Toutefois, il n'y a pas de véritable tendance. En effet, certaines marques pourtant situées à la fin du classement présentent des prix moyens élevés. L'impact de la popularité de la marque sur le prix n'est pas si évident. Ceci sera analysé plus en détail en liant la popularité de la marque à la popularité des articles puis ensuite à l'aide de la régression linéaire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.6 **Lien entre la popularité de la marque et de l'article**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons réalisé ce graphique pour vérifier si la popularité globale des marques, mesurée par leur rang dans des classements externes, était en corrélation avec leur popularité sur eBay, représentée par le coefficient de popularité. L’objectif était de déterminer si les marques mieux classées globalement (avec un rang plus faible) étaient également les plus prisées par les acheteurs sur eBay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Remplacer les valeurs nulles par des zéros pour éviter les exclusions\n",
    "df['Rang'] = df['Rang'].fillna(0)\n",
    "df['Coefficient'] = df['Coefficient'].fillna(0)\n",
    "\n",
    "# Calculer les moyennes par marque\n",
    "brand_stats = df.groupby('Marque').agg(\n",
    "    Avg_Rang=('Rang', 'mean'), \n",
    "    Avg_Coefficient=('Coefficient', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Calculer la corrélation\n",
    "correlation, p_value = pearsonr(brand_stats['Avg_Rang'], brand_stats['Avg_Coefficient'])\n",
    "\n",
    "# Définir le style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Créer la figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Scatter plot\n",
    "sns.scatterplot(\n",
    "    data=brand_stats, \n",
    "    x='Avg_Rang', \n",
    "    y='Avg_Coefficient', \n",
    "    hue='Marque', \n",
    "    palette='coolwarm', \n",
    "    s=100\n",
    ")\n",
    "\n",
    "# Ajouter une ligne de tendance\n",
    "sns.regplot(\n",
    "    data=brand_stats, \n",
    "    x='Avg_Rang', \n",
    "    y='Avg_Coefficient', \n",
    "    scatter=False, \n",
    "    color='gray', \n",
    "    line_kws={\"linestyle\": \"dashed\"}\n",
    ")\n",
    "\n",
    "# Ajouter des annotations\n",
    "for i, row in brand_stats.iterrows():\n",
    "    plt.text(\n",
    "        row['Avg_Rang'] + 0.1, \n",
    "        row['Avg_Coefficient'], \n",
    "        row['Marque'], \n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "# Ajouter des titres et labels\n",
    "plt.title('Relation entre le Rang des Marques et le Coefficient de Popularité', fontsize=16, weight='bold')\n",
    "plt.xlabel('Rang Moyen des Marques (Plus Bas = Plus Populaire)', fontsize=14)\n",
    "plt.ylabel('Coefficient de Popularité Moyen', fontsize=14)\n",
    "plt.legend(title=\"Marques\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher la corrélation\n",
    "plt.figtext(0.15, -0.05, f\"Corrélation : {correlation:.2f} (p-value: {p_value:.2e})\", fontsize=12, color=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique montre qu’il n’existe pas de relation significative entre le rang global des marques et leur coefficient de popularité sur eBay. En effet, la corrélation calculée est proche de zéro, indiquant une absence de lien statistique. Par exemple, des marques comme Asus (rang 1) et Apple (rang 3), bien positionnées globalement, affichent des coefficients de popularité similaires à ceux de marques comme Lenovo (rang 8) ou HP (rang 5), qui sont moins bien classées. Cela suggère que la popularité des articles sur eBay dépend d’autres facteurs tels que le prix, les modèles spécifiques disponibles ou encore les promotions, plutôt que du classement global des marques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7  **Analyse de la temporalité**\n",
    "\n",
    "\n",
    "Il nous reste à observer la temporalité. On peut supposer que la période de l'année à laquelle l'annonce est publiée pourrait avoir un effet sur le prix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_price_per_month(df):\n",
    "    # Extraire le mois\n",
    "    df['Mois'] = df['Date de publication'].dt.month\n",
    "    \n",
    "    # Moyenne et médiane des prix par mois\n",
    "    avg_price_per_month = df.groupby('Mois')['Prix'].mean()\n",
    "    median_price_per_month = df.groupby('Mois')['Prix'].median()\n",
    "\n",
    "    # Compter le nombre d'ordinateurs vendus par mois\n",
    "    count_per_month = df['Mois'].value_counts().sort_index()\n",
    "    print(\"Nombre d'ordinateurs vendus par mois :\\n\", count_per_month)\n",
    "\n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(avg_price_per_month.index, avg_price_per_month.values, marker='o', label='Prix moyen', color='skyblue')\n",
    "    plt.plot(median_price_per_month.index, median_price_per_month.values, marker='o', label='Prix médian', color='orange')\n",
    "    plt.title(\"Prix moyen et médian des ordinateurs portables par mois\", fontsize=16)\n",
    "    plt.xlabel(\"Mois\", fontsize=14)\n",
    "    plt.ylabel(\"Prix (€)\", fontsize=14)\n",
    "    plt.xticks(range(1, 13), ['Jan', 'Fév', 'Mar', 'Avr', 'Mai', 'Juin', 'Juil', 'Août', 'Sep', 'Oct', 'Nov', 'Déc'], fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "avg_price_per_month(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons choisi d'afficher à la fois le prix moyen par mois et le prix médian. En effet, comme la collecte des données a commencé en décembre, le nombre d'annonces publiées en décembre est largement supérieur à celui des autres mois. Ainsi, la nette supériorité du prix moyen en décembre pourrait s'expliquer par un manque de données pour les autres mois. C'est pourquoi le prix médian apparaît comme une mesure plus pertinente dans cette analyse. Toutefois, la tendance observée avec le prix moyen reste la même : le prix médian en décembre est supérieur à celui des autres mois. \n",
    "\n",
    "Une explication possible pourrait être l'approche des fêtes de fin d'année, qui incite les vendeurs à proposer leurs ordinateurs portables à un prix plus élevé, sachant que la demande pour ces produits augmente durant cette période. \n",
    "Toutefois, il est possible que nous faisions face à un biais de récolte de données. En effet, les données récoltées représentent uniquement les annonces encore actives et invendues à ce moment-là. Les données sur les ordinateurs vendus lors des mois précédents, sûrement plus compétitifs, ne sont pas disponibles ce qui nous encourage à être prudent sur cette analyse.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Modélisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle que nous avons choisi dans le cadre de ce projet est le modèle de régression linéaire. Nous avons choisi ce modèle car il est simple à comprendre et à interpréter, et il est également rapide à entraîner. Nous allons entraîner un modèle de régression linéaire pour prédire le prix des ordinateurs portables en fonction de certaines de leurs caractéristiques.\n",
    "\n",
    "Nous utiliserons la bibliothèque *scikit-learn* afin de coder le modèle. \n",
    "\n",
    "### **5.1 Prétraitement des données**\n",
    "\n",
    "#### 5.1.1 **Encodage des colonnes catégoriques**\n",
    "\n",
    "Nous commençons par encoder les colonnes catégoriques, à savoir *Marque*, *Couleur* et *Condition*. Pour ce faire, nous transformons chaque catégorie en une variable binaire (*dummy*). Cette méthode permet d'identifier l'effet de chaque catégorie sans introduire de relation ordinale entre elles, contrairement à un encodage numérique simple tel que celui de la colonne *Rang*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Marque', 'Condition','Couleur'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la colonne Date de publication, nous avons observé que l'effet sur le prix dépend principalement de si l'annonce a été publiée en décembre. Par conséquent, nous avons créé une variable binaire Décembre qui prend la valeur 1 si l'annonce a été publiée en décembre, et 0 sinon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = pd.to_datetime(df['Date de publication']).dt.month\n",
    "df['December'] = df['Month'].apply(lambda x: 1 if x == 12 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime ensuite les colonnes inutiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID','Date de publication','Month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 **Gestion des valeurs manquantes**\n",
    "\n",
    "Notre première approche a été de remplacer les valeurs manquantes pour les colonnes numériques par la médiane des valeurs. Mais nous avons remarqué que la prédiction était peu satisfaisante ($R^2 < 0.5$). Nous avons alors chercher à mieux gérer les valeurs manquantes.  \n",
    "\n",
    "Après quelques recherches, nous avons opté pour l'imputation **KNN (K-Nearest Neighbors)**. Contrairement à l'imputation par la médiane, qui remplace les valeurs manquantes par une valeur fixe, l'imputation KNN utilise les valeurs des k voisins les plus proches pour estimer les valeurs manquantes. Cette méthode est souvent plus précise car elle prend en compte la similarité entre les observations. En utilisant les k voisins les plus proches, l'imputation KNN peut capturer des relations plus complexes dans les données, ce qui peut améliorer les performances du modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour préparer les données pour le modèle de machine learning, nous avons défini les variables explicatives (*features*) et la variable cible (*target*). \n",
    "\n",
    "Les features sont toutes les colonnes du DataFrame `df_imputed` à l'exception de la colonne *Prix*. La variable cible, y, est la colonne *Prix* transformée logarithmiquement. Cette transformation logarithmique est appliquée pour normaliser les données et réduire l'effet des valeurs extrêmes, ce qui améliore la qualité du modèle d'après les tests que nous avons effectué.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_imputed.drop(columns=['Prix'])\n",
    "y = np.log(df_imputed['Prix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3 **Normalisation des valeurs**\n",
    "\n",
    "La normalisation est une étape importante dans le prétraitement des données, surtout pour les algorithmes de machine learning sensibles à l'échelle des données. \n",
    "\n",
    "Nous avons standardisé les caractéristiques en supprimant la moyenne et en les redimensionnant à l'unité de variance. Ensuite, nous avons ajusté et transformé les données. Le résultat est un tableau numpy contenant les caractéristiques normalisées, prêtes à être utilisées pour l'entraînement du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalisation des caractéristiques\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.4 **Séparation des données en ensembles d'entraînement et de test**\n",
    "\n",
    "La séparation des données en ensembles d'entraînement et de test est essentielle pour évaluer objectivement la performance d'un modèle de machine learning. Nous avons choisi un ensemble d'entraînement qui représente 80% des données, il est utilisé pour entraîner le modèle, tandis que notre ensemble de test, les 20% restants, permet de vérifier la capacité du modèle à généraliser sur des données non vues. \n",
    "\n",
    "Cette pratique aide à prévenir le surajustement (*Overfitting*), où le modèle apprend trop bien les détails des données d'entraînement au détriment de sa performance sur de nouvelles données. En évaluant le modèle sur l'ensemble de test, nous pouvons nous assurer qu'il performe bien avant de le déployer en production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 **Exécution du modèle**\n",
    "\n",
    "#### 5.2.1 **Le modèle de régression linéaire**\n",
    "\n",
    "Nous avons entraîné le modèle en utilisant les données d'entraînement avec la méthode fit *(X_train, y_train)*. Cette méthode ajuste le modèle aux données d'entraînement, apprenant ainsi les relations entre les caractéristiques (*features*) et la variable cible (*target*).\n",
    "\n",
    "Après l'entraînement, nous avons utilisé le modèle pour faire des prédictions sur l'ensemble de test. Les prédictions, stockées dans *y_pred*, représentent les valeurs prévues par le modèle pour les données de test.\n",
    "\n",
    "Pour comprendre l'importance de chaque caractéristique dans le modèle, nous avons affiché les coefficients du modèle. Cela nous permet de voir l'impact de chaque caractéristique sur la variable cible.\n",
    "\n",
    "Enfin, nous avons évalué la performance du modèle en utilisant plusieurs métriques:\n",
    "\n",
    "* Le $R²$ **Score** mesure la proportion de la variance de la variable cible expliquée par les caractéristiques.  \n",
    "\n",
    "* Le **$MAE$ (Mean Absolute Error)** mesure l'erreur moyenne absolue entre les prédictions et les valeurs réelles.  \n",
    "\n",
    "* Le **$RMSE$ (Root Mean Squared Error)** mesure l'erreur quadratique moyenne entre les prédictions et les valeurs réelles. Ces métriques nous donnent une idée de la précision et de la fiabilité du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Initialisation du modèle\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Afficher les coefficients du modèle\n",
    "coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "print(coefficients.round(3))\n",
    "\n",
    "# Évaluation du modèle\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 **Interprétation des résultats**\n",
    "\n",
    "##### 1. **Caractéristiques techniques**\n",
    "Les caractéristiques techniques comme la **RAM** ($0.247$) et le **PPI** ($0.292$) restent les plus influentes dans la détermination des prix, ce qui souligne leur importance perçue par les consommateurs. Le **Stockage** ($0.128$) et la **Taille de l’écran** ($0.097$) ont un impact moindre, mais ils contribuent également positivement au prix, reflétant leurs rôles dans la valeur perçue.\n",
    "\n",
    "##### 2. **Popularité des marques et des produits**\n",
    "**Rang** ($-0.105$) : Les marques moins populaires dans les classements ont tendance à afficher des prix plus bas. Ce résultat est intuitif, car une moindre popularité peut être associée à une perception de qualité ou de prestige inférieure. \n",
    "\n",
    "**Coefficient de popularité** ($-0.024$) : Les produits avec des indices de popularité plus élevés ne bénéficient que faiblement d'une prime sur le prix. Cette faible corrélation peut s’expliquer par une saturation du marché : les consommateurs achètent des produits populaires sans nécessairement payer une prime importante.\n",
    "\n",
    "##### 3. **Effet des marques**\n",
    "L'effet des marques reflète leur positionnement :\n",
    "\n",
    "*Apple* ($0.202$) reste la marque qui influence le plus fortement le prix, soulignant son prestige et son image haut de gamme.\n",
    "Les autres marques comme *Dell* ($0.099$), *Lenovo* ($0.097$) et *HP* ($0.039$) montrent une influence positive mais modérée, tandis que *Asus* ($0.007$) reste quasi neutre.  \n",
    "*Marques autres* ($0.060$) : Ce groupe montre que même des marques moins connues peuvent maintenir un prix relativement compétitif.\n",
    "\n",
    "##### 4. **Conditions des produits**\n",
    "Les coefficients pour les conditions sont cohérents avec les attentes du marché :\n",
    "\n",
    "Les ordinateurs occasion ($-0.233$), état correct ($-0.140$) ou très bon état ($-0.137$) subissent des décotes importantes par rapport au neuf.\n",
    "Les produits en parfait état ($-0.076$) ou ouvert ($0.002$) montrent une décote plus faible, confirmant que l’état proche du neuf est perçu positivement.\n",
    "\n",
    "##### 5. **Variables temporelles et esthétiques**\n",
    "**December** ($0.046$) : Cela indique que les ordinateurs portables publiés en décembre ont tendance à être légèrement plus chers. On retrouve bien l'effet observé plus haut. Malheureusement, le modèle ne nous aide pas à identifier un effet causal clair.\n",
    "\n",
    "**Couleurs** : Les coefficients des couleurs (par exemple, gris ($0.068$), blanc ($-0.032$)) montrent des impacts marginaux, ce qui suggère que l’esthétique a une influence très faible sur le prix.\n",
    "\n",
    "##### 6. **Qualité du modèle**\n",
    "$R²$ **Score** ($0.59$) indique que 59 % de la variance des prix est expliquée par le modèle.  \n",
    "Les métriques d’erreur ($MAE : 0.38$ et $RMSE : 0.25$) confirment une bonne précision globale.\n",
    "\n",
    "En conclusion, le prix des ordinateurs portables est majoritairement influencé par leurs caractéristiques techniques et la notoriété des marques. La popularité des articles et le rang des marques jouent un rôle négatif mais relativement limité, indiquant que les consommateurs se concentrent davantage sur la valeur intrinsèque du produit et la réputation globale de la marque. Les conditions des produits ont une importance capitale, tandis que les aspects esthétiques et temporels restent secondaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons entrepris une analyse détaillée des données des ordinateurs portables pour comprendre les facteurs influençant leur prix et développer un modèle de prédiction précis. Nous avons récupéré les données produits via l'API d'eBay ainsi que des données concernant la popularité des produits via le scraping de plusieurs sites. Après avoir nettoyé les donnéees et filtrer les valeurs aberrantes, nous avons pu identifier les relations entre les différentes caractéristiques des produits, à la fois techniques et de préférence. La partie visualisation ainsi que le modèle de régression linéaire nous ont permis de comprendre que les caractéristiques techniques tels que la RAM, la densité de pixels ou encore la taille de l'écran étaient les principaux facteurs de fixation du prix tandis que les préférences jouaient un rôle secondaire, à l'exception des produits de la marque Apple dont le prix est nettement plus élevé que toutes les autres marques à caractéristiques similaires. \n",
    "\n",
    "Notre modèle nous permet ainsi d'estimer le prix d'un ordinateur portable en fonction de ses différentes caractéristiques de manière plutôt précise. Une extension de notre projet pourrait ainsi être le développement d'une fonctionnalité qui pourrait être integrée aux sites de e-shopping tels que eBay, qui permetrait de donner le prix de marché de son produit au vendeur lorsqu'il rentre les caractéristiques de son produit pour publier son annonce."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
