{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analyse des tendances de prix des ordinateurs portables sur eBay**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Notre projet vise à étudier les tendances de consommation des utilisateurs de plateformes de e-commerce, en se concentrant sur les ordinateurs portables sur eBay. Les questions centrales de cette étude sont les suivantes :\n",
    "- Quels sont les facteurs qui influencent la demande d’un produit et, par conséquent, son prix ?\n",
    "- Comment estimer le prix d’un ordinateur en fonction de ses caractéristiques ?\n",
    "\n",
    "Pour y répondre, nous avons distingué deux types de critères :\n",
    "\n",
    "**Critères objectifs :** RAM, stockage, densité de pixels, condition de l’article.\n",
    "\n",
    "**Critères subjectifs :** marque, couleur, taille de l’écran.\n",
    "\n",
    "Nous avons trouvé le choix de la plateforme eBay pertinent dans la mesure où ce sont les utilisateurs qui fixent le prix qu'ils attribuent à leur ordinateur. Cette dynamique permet d’évaluer si les vendeurs sont objectifs dans leur valorisation du produit ou si le prix fixé est cohérent avec les caractéristiques de l’ordinateur. Grâce aux tendances observées, il devient possible de déterminer si ces prix reflètent réellement la valeur des produits.\n",
    "\n",
    "Afin d’analyser ces influences, nous avons choisi de modéliser la relation entre les caractéristiques des produits et leur prix à l’aide d’une régression linéaire. Cette approche permet de quantifier l’impact de chaque critère sur le prix des ordinateurs portables. Nous pourrons ainsi mieux comprendre comment les utilisateurs déterminent le prix de vente de leurs ordinateurs portables et savoir si certaines variables les influencent plus que d'autres. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n",
      "ERROR: No matching distribution found for re\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\antony\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.5.3)\n",
      "Requirement already satisfied: requests in c:\\users\\antony\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\antony\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\antony\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\antony\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.12.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\antony\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chargement des données dans le projet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En raison du temps de réponse élevé de l’API et du nombre d'appels à l'API limité à 4500 par jour, nous avons préféré exécuter les requêtes en amont et sauvegarder les données dans un fichier CSV. Cette démarche a pour objectif de faciliter l’analyse en évitant les délais d’attente liés à l’API et en permettant d'avoir plus de données. \n",
    "\n",
    "Le code permettant de collecter les données est disponible sur le GitHub du projet. Ce script **data.py** situé dans le fichier **src** peut être exécuté en suivant les instructions du README pour l'accès à l'API si de nouvelles données doivent être extraites.\n",
    "\n",
    "Dans le notebook, nous nous contentons de charger le fichier CSV prégénéré pour effectuer les étapes d’analyse et de nettoyage.\n",
    "\n",
    "Cette approche permet une expérience plus fluide et garantit la reproductibilité de l’étude sans dépendre des performances de l’API au moment de l’exécution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Récupération des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pour collecter les données nécessaires à notre étude, nous avons utilisé l’API Browse d’eBay. Ce choix s’explique par la richesse des informations disponibles sur cette plateforme et son large catalogue de produits. Cependant, cela a requis plusieurs étapes préparatoires :\n",
    "\n",
    "1. **Choix d'un segment spécifique :** Pour limiter la variabilité des données, nous avons choisi de nous concentrer sur les ordinateurs portables. Ce segment présente de nombreuses spécificités (RAM, stockage, écran, etc.) qui permettent d’étudier l’impact de chaque critère sur le prix.\n",
    "\n",
    "2. **Délimitation du marché :** Nous avons choisi de nous focaliser sur le marché français. Cette décision a pour but d’éviter les biais liés à des contextes géopolitiques différents entre les marchés ou à des devises différentes. \n",
    "\n",
    "3. **Extraction des données :**\n",
    "Les informations classiques comme le prix et l’état des articles sont directement accessibles via l’API Browse pour chaque item.\n",
    "Les caractéristiques plus précises (RAM, marque, stockage, taille de l’écran) sont stockées dans une sous-catégorie nommée localized aspects. Ces informations sont organisées sous forme de dictionnaire (clé/valeur).\n",
    "\n",
    "4. **Gestion des données manquantes :**\n",
    "Comme les utilisateurs remplissent eux-mêmes les informations, certaines données sont parfois absentes. \n",
    "Plusieurs approches ont été envisagées :\n",
    "- Exclure les articles avec des données manquantes, en raison du volume important de données disponibles.\n",
    "- Conserver les articles incomplets pour ne pas réduire excessivement l’échantillon.\n",
    "\n",
    "Afin de ne pas trop réduire l'échantillon ou de compromettre la fiabilité de l'étude nous avons choisi de conserver les articles ayant obligatoirement les informations suivantes : prix, capacité de stockage, RAM et marque. Toutefois, si des données telles que la taille de l'écran, la résolution ou encore la date de publication ne sont pas présentes il ne nous semblait pas pertinent d'enlever ces ordinateurs portables puisque cela ne compromet pas le résultat de notre étude et nous permet d'avoir un échantillon plus important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Condition</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Stockage</th>\n",
       "      <th>Marque</th>\n",
       "      <th>Couleur</th>\n",
       "      <th>Taille écran</th>\n",
       "      <th>Résolution</th>\n",
       "      <th>Date de publication</th>\n",
       "      <th>Rang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v1|176737201854|0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>16 Go</td>\n",
       "      <td>0</td>\n",
       "      <td>ASUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,4\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-15T17:33:06.000Z</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v1|375863586836|0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>8 Go</td>\n",
       "      <td>256 Go</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Gris</td>\n",
       "      <td>13\"</td>\n",
       "      <td>2560 x 1600</td>\n",
       "      <td>2024-12-13T08:42:48.000Z</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v1|146269671817|0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>6 Go</td>\n",
       "      <td>700Go</td>\n",
       "      <td>ASUS</td>\n",
       "      <td>Rouge</td>\n",
       "      <td>15,6\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-15T11:51:11.000Z</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v1|196898961056|0</td>\n",
       "      <td>89.9</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>8 Go</td>\n",
       "      <td>480Go</td>\n",
       "      <td>HP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17,3\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-17T16:37:02.000Z</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v1|365291982473|0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>Occasion</td>\n",
       "      <td>16 Go</td>\n",
       "      <td>256 Go</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Noir</td>\n",
       "      <td>13\"</td>\n",
       "      <td>1920 x 1080</td>\n",
       "      <td>2024-12-17T16:57:08.000Z</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID    Prix Condition    RAM Stockage Marque Couleur  \\\n",
       "0  v1|176737201854|0  1680.0  Occasion  16 Go        0   ASUS     NaN   \n",
       "1  v1|375863586836|0   550.0  Occasion   8 Go   256 Go  Apple    Gris   \n",
       "2  v1|146269671817|0   120.0  Occasion   6 Go    700Go   ASUS   Rouge   \n",
       "3  v1|196898961056|0    89.9  Occasion   8 Go    480Go     HP     NaN   \n",
       "4  v1|365291982473|0  1300.0  Occasion  16 Go   256 Go   Dell    Noir   \n",
       "\n",
       "  Taille écran   Résolution       Date de publication  Rang  \n",
       "0        13,4\"          NaN  2024-12-15T17:33:06.000Z   5.0  \n",
       "1          13\"  2560 x 1600  2024-12-13T08:42:48.000Z   1.0  \n",
       "2        15,6\"          NaN  2024-12-15T11:51:11.000Z   5.0  \n",
       "3        17,3\"          NaN  2024-12-17T16:37:02.000Z   3.0  \n",
       "4          13\"  1920 x 1080  2024-12-17T16:57:08.000Z   7.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordi_csv = \"data3.csv\"\n",
    "df = pd.read_csv(ordi_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nettoyage des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme évoqué plus tôt, la particularité des données récoltées est qu'elles ont été entrées par les vendeurs eux-mêmes via la plateforme. Ainsi, si le nom de la catégorie (ex: 'RAM', 'Stockage') est le même pour chaque produit, les informations contenues dans chaque colonne différent dans leur format. Par défaut, toutes les données sont de type \"object\" ce qui ne les rend pas exploitable directement pour nous. Le travail de nettoyage est ainsi essentiel afin d'avancer sur notre projet.  \n",
    "\n",
    "1) **Nettoyage des données chiffrées**\n",
    "\n",
    "Pour cela, nous avons créé une fonction **extract_float_from_object** au sein du fichier **utils.py** qui permet d'extraire un nombre de type float à partir d'une chaîne de caractère. Nous pouvons appliquer cette fonction directement pour la catégorie 'Taille écran'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import extract_float_from_object\n",
    "\n",
    "def extract_taille_ecran(df):\n",
    "    df['Taille écran'] = df['Taille écran'].apply(extract_float_from_object)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour gérer les catégories liées au stockage dont les données étaient soit rentrées en Go, soit en To, nous avons créé une seconde fonction dérivée de la première, mais qui effectue la conversion en Go pour les données entrées en To, selon la formule **1To = 1024Go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import extract_storage\n",
    "\n",
    "def clean_giga_columns(df):\n",
    "    df['RAM'] = df['RAM'].apply(extract_storage)\n",
    "    df['Stockage'] = df['Stockage'].apply(extract_storage)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, pour gérer la colonne résolution dont le format est le suivant : **Largeur x Hauteur'**, nous avons choisi de combiner cette information avec la taille de l'écran pour établir une mesure comparable entre tous les ordinateurs du data frame : la densité de pixels (PPI).\n",
    "\n",
    "$$\n",
    "Densité\\ de\\ pixels = \\frac{\\sqrt{\\text{largeur}^2 + \\text{hauteur}^2}}{\\text{taille de l'écran en pouces}}\n",
    "$$\n",
    "\n",
    "On commence par extraire la largeur et la hauteur dans deux nouvelles colonnes, et on utilise ensuite la formule ci-dessus pour créer la colonne **PPI** que l'on conservera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resolution(df):\n",
    "    df[['Largeur', 'Hauteur']] = df['Résolution'].str.extract(r'(\\d+)[\\s]*[xX][\\s]*(\\d+)', expand=True)\n",
    "    df[['Largeur', 'Hauteur']] = df[['Largeur', 'Hauteur']].apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "def calculate_ppi(df):\n",
    "    df['Taille écran'] = df['Taille écran'].apply(extract_float_from_object)\n",
    "    df[['Largeur', 'Hauteur', 'Taille écran']] = df[['Largeur', 'Hauteur', 'Taille écran']].replace(0, np.nan)\n",
    "    # On calcule le PPI uniquement pour les lignes où toutes les valeurs nécessaires sont présentes\n",
    "    mask = df[['Largeur', 'Hauteur', 'Taille écran']].notnull().all(axis=1)\n",
    "    df.loc[mask, 'PPI'] = np.round(np.sqrt(df.loc[mask, 'Largeur']**2 + df.loc[mask, 'Hauteur']**2) / df.loc[mask, 'Taille écran'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Nettoyage des données temporelles**\n",
    "\n",
    "Cela concerne uniquement la colonne **Date de publication**. Ici, le format est idéal car c'est une information qui nous est fournie directement par eBay. On utilise alors la fonction intégrée à pandas **pd.to_datetime()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(df):\n",
    "    df['Date de publication'] = pd.to_datetime(df['Date de publication'], errors='coerce')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Nettoyage des données textuelles**\n",
    "\n",
    "Cela concerne les colonnes **Condition**, **Marque** et **Couleur**. Ici, l'enjeu est d'uniformiser les données afin de rassembler toutes les données identiques de fait mais rentrées différemment par les utilisateurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation des couleurs\n",
    "def normalize_color(color):\n",
    "    if isinstance(color, str):\n",
    "        color = color.lower()\n",
    "        if 'gris' in color or 'silver' in color or 'argent' in color or 'argenté' in color or 'grey' in color and 'graphite' in color:\n",
    "            return 'gris'\n",
    "        elif 'noir' in color or 'black' in color:\n",
    "            return 'noir'\n",
    "        elif 'blanc' in color or 'white' in color:\n",
    "            return 'blanc'\n",
    "        elif 'bleu' in color or 'midnight' in color or 'blue' in color:\n",
    "            return 'bleu'\n",
    "        elif 'rouge' in color or 'red' in color:\n",
    "            return 'rouge'\n",
    "        elif 'vert' in color or 'green' in color:\n",
    "            return 'vert'\n",
    "        elif 'jaune' in color or 'yellow' in color:\n",
    "            return 'jaune'\n",
    "        elif 'rose' in color or 'pink' in color:\n",
    "            return 'rose'\n",
    "        elif 'marron' in color or 'brown' in color:\n",
    "            return 'marron'\n",
    "        elif 'violet' in color or 'purple' in color:\n",
    "            return 'violet'\n",
    "    return \"autre\"\n",
    "\n",
    "def clean_color_column(df):\n",
    "    df['Couleur'] = df['Couleur'].apply(normalize_color)\n",
    "    return df\n",
    "\n",
    "#Normalisation des conditions \n",
    "def convertir_condition(condition):\n",
    "    \"\"\" \n",
    "    Crée une classification des conditions des produits du meilleur au pire\n",
    "    \"\"\"\n",
    "    if \"Neuf\" in condition:\n",
    "        return \"Neuf\"\n",
    "    elif \"Ouvert (jamais utilisé)\" in condition:\n",
    "        return \"Ouvert\"\n",
    "    elif 'Parfait état - Reconditionné' in condition: \n",
    "        return \"Parfait état\"\n",
    "    elif 'Très bon état - Reconditionné' in condition:\n",
    "        return \"Très bon état\"\n",
    "    elif 'État correct - Reconditionné' in condition:\n",
    "        return \"État correct\"\n",
    "    elif 'Occasion' in condition: \n",
    "        return \"Occasion\"\n",
    "    \n",
    "def clean_condition(df):\n",
    "    df['Condition'] = df['Condition'].apply(convertir_condition)\n",
    "    return df\n",
    "\n",
    "#Normalisation des marques\n",
    "def format_marque(marque):\n",
    "    if isinstance(marque, str):\n",
    "        marque = marque.lower()\n",
    "        if any(substring in marque for substring in ['carte graphique', 'nvidia']):\n",
    "            return np.nan #Ici, on élimine également les lignes qui ne correspondent \n",
    "                          #pas à des ordinateurs portables, rentrées par erreur\n",
    "        elif 'apple' in marque or 'macbook' in marque:\n",
    "            return 'Apple'\n",
    "        elif 'dell' in marque or 'del' in marque:\n",
    "            return 'Dell'\n",
    "        elif 'hp' in marque:\n",
    "            return 'HP'\n",
    "        elif 'lenovo' in marque:\n",
    "            return 'Lenovo'\n",
    "        elif 'asus' in marque:\n",
    "            return 'Asus'\n",
    "        elif 'acer' in marque:\n",
    "            return 'Acer'\n",
    "        elif 'samsung' in marque:\n",
    "            return 'Samsung'\n",
    "        elif 'sony' in marque:\n",
    "            return 'Sony'\n",
    "        elif 'toshiba' in marque:\n",
    "            return 'Toshiba'\n",
    "        elif 'huawei' in marque:\n",
    "            return 'Huawei'\n",
    "        elif 'msi' in marque:\n",
    "            return 'MSI'\n",
    "        elif 'panasonic' in marque:\n",
    "            return 'Panasonic'\n",
    "        elif 'microsoft' in marque:\n",
    "            return 'Microsoft'\n",
    "        elif 'lg' in marque:\n",
    "            return 'LG'\n",
    "        elif 'google' in marque:\n",
    "            return 'Google'\n",
    "        elif 'alienware' in marque:\n",
    "            return 'Alienware'\n",
    "        elif 'razer' in marque:\n",
    "            return 'Razer'\n",
    "        elif 'gigabyte' in marque:\n",
    "            return 'Gigabyte'\n",
    "        elif 'clevo' in marque:\n",
    "            return 'Clevo'\n",
    "        elif 'fujitsu' in marque:\n",
    "            return 'Fujitsu'\n",
    "        elif 'medion' in marque:\n",
    "            return 'Medion'\n",
    "        elif 'xmg' in marque:\n",
    "            return 'XMG'\n",
    "        elif 'chuwi' in marque:\n",
    "            return 'Chuwi'\n",
    "        elif 'jumper' in marque:\n",
    "            return 'Jumper'\n",
    "        elif 'teclast' in marque:\n",
    "            return 'Teclast'\n",
    "        elif 'voyo' in marque:\n",
    "            return 'Voyo'\n",
    "        elif 'bmax' in marque:\n",
    "            return 'BMAX'\n",
    "        elif 'one-netbook' in marque:\n",
    "            return 'One-Netbook'\n",
    "        elif 'gpd' in marque:\n",
    "            return 'GPD'\n",
    "        elif 'tuxedo' in marque:\n",
    "            return 'Tuxedo'\n",
    "        elif 'system76' in marque:\n",
    "            return 'System76'\n",
    "        elif 'purism' in marque:\n",
    "            return 'Purism'\n",
    "        elif 'pine64' in marque:\n",
    "            return 'Pine64'\n",
    "        elif 'minisforum' in marque:\n",
    "            return 'Minisforum'\n",
    "        elif 'azulle' in marque:\n",
    "            return 'Azulle'\n",
    "        elif 'beelink' in marque:\n",
    "            return 'Beelink'\n",
    "        elif 'meego' in marque:\n",
    "            return 'Meego'\n",
    "        elif 'vorke' in marque:\n",
    "            return 'Vorke'\n",
    "        elif 'trigkey' in marque:\n",
    "            return 'Trigkey'\n",
    "        elif 'acepc' in marque:\n",
    "            return 'ACEPC'\n",
    "        elif 'awow' in marque:\n",
    "            return 'AWOW'\n",
    "        elif 'niuniutab' in marque:\n",
    "            return 'Niuniutab'\n",
    "        else:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "def clean_brand_column(df):\n",
    "    df['Marque'] = df['Marque'].apply(format_marque)\n",
    "    df = df.dropna(subset=['Marque'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut à présent exécuter toutes ces fonctions afin de générer un nouveau data frame exploitable **data_semicleaned.csv**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m clean_giga_columns(df)\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m clean_color_column(df)\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m extract_resolution(df)\n",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m, in \u001b[0;36mclean_giga_columns\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_giga_columns\u001b[39m(df):\n\u001b[1;32m----> 4\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAM\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(extract_storage)\n\u001b[0;32m      5\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStockage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStockage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(extract_storage)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df = clean_giga_columns(df)\n",
    "df = clean_color_column(df)\n",
    "df = extract_resolution(df)\n",
    "df = extract_taille_ecran(df)\n",
    "df = convertir_condition(df)\n",
    "df = calculate_ppi(df)\n",
    "df = format_date(df)\n",
    "df = clean_brand_column(df)\n",
    "df = format_date(df)\n",
    "df = df.drop(['Largeur', 'Hauteur', 'Résolution'], axis=1)\n",
    "#la colonne résolution est remplacée par la colonne PPI qui compile taille de l'écran et résolution\n",
    "\n",
    "df.to_csv('data_semicleaned.csv', index=False) \n",
    "#génération d'un nouveau csv pour les données formatées "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir notre data frame final, il reste encore à gérer les valeurs aberrantes qui sont assez fréquentes du fait des erreurs ou mauvais choix des utilisateurs eBay.\n",
    "\n",
    "4. **Gestion des valeurs aberrantes**\n",
    "\n",
    "Un bon outil pour repérer les valeurs aberrantes est la boîte à moustache qui nous donne une vision claire de la répartition des données pour chaque catégorie. On peut la générer pour chaque colonne grâce à la fonction suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_semicleaned.csv')\n",
    "\n",
    "def boxplot(df, column_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=df[column_name])\n",
    "    plt.title(f'Boxplot of {column_name}')\n",
    "    plt.xlabel(column_name)\n",
    "    plt.show()\n",
    "\n",
    "boxplot(df, 'Prix')\n",
    "#boxplot(df, 'Stockage')\n",
    "#boxplot(df, 'RAM')\n",
    "#boxplot(df, 'PPI')\n",
    "#boxplot(df, 'Taille écran')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce à ces boites à moustache ainsi qu'un peu de logique, on établit une plage cohérente pour chaque colonne. Toute donnée à l'extérieur de ces plages est considérée comme \"aberrante\" et est gérée en fonction. \n",
    "\n",
    "**Caractéristiques des plages** :\n",
    "\n",
    "- **Plage des prix** : $[50\\ € ;\\ 3000\\ €]$\n",
    "- **Plage de la densité de pixels** : $[80\\ \\text{PPI} ;\\ 300\\ \\text{PPI}]$\n",
    "- **Plage de la capacité de stockage** : $[32\\ \\text{Go} ;\\ 4000\\ \\text{Go}]$\n",
    "- **Plage de la capacité de RAM** : $[2\\ \\text{Go} ;\\ 64\\ \\text{Go}]$\n",
    "- **Plage de la taille d’écran** : $[6'' ;\\ 20'']$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Prix'] >= 50) & (df['Prix'] <= 3000)]  \n",
    "df.loc[(df['PPI'] > 300) | (df['PPI'] < 80), 'PPI'] = np.nan\n",
    "# énormément de gens se trompent en mettant la même valeur pour la RAM et le stockage\n",
    "df.loc[(df['Stockage'] < 32) | (df['Stockage'] > 4000), 'Stockage'] = np.nan  \n",
    "df.loc[(df['RAM'] < 2) | (df['RAM'] > 64), 'RAM'] = np.nan  \n",
    "df.loc[(df['Taille écran'] < 6) | (df['Taille écran'] > 20), 'Taille écran'] = np.nan  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etant donné que l'on cherche à estimer le prix, on a décidé de supprimer les lignes où les prix étaient aberrants. Pour les autres variables, on a décidé de les remplacer par des **NaN** pour les exclure de la visualisation sans se priver de l'information que nous apporte les autres données de cet ordinateur.\n",
    "\n",
    "On peut à présent générer notre data frame nettoyé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modélisation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
